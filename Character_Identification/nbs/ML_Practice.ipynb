{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = '../labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob.glob(os.path.join(data_path, '*.Bmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = glob.glob(os.path.join(data_path, '2290.Bmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/2290.Bmp']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = pd.read_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'q'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels[data_labels.ID==int(re.findall('\\d+', file[0])[0])].Class.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\n"
     ]
    }
   ],
   "source": [
    "# resize images and convert images to arrays, meanwhile load their labels. Convert graylevel images to 3 channels.\n",
    "data_X = []\n",
    "data_y = []\n",
    "flag = 25\n",
    "for i, fname in enumerate(filelist):\n",
    "    if i==flag:\n",
    "        img = Image.open(fname)\n",
    "        print(data_labels[data_labels.ID==int(re.findall('\\d+', fname)[0])].Class.iloc[0])\n",
    "    data_y.append(data_labels[data_labels.ID==int(re.findall('\\d+', fname)[0])].Class.iloc[0])\n",
    "    img_arr = np.array(Image.open(fname).resize((28,28), Image.NEAREST))\n",
    "#    print(img_arr.shape)\n",
    "    if len(img_arr.shape)==2:\n",
    "        img_arr = np.stack((img_arr,)*3, -1)\n",
    "    data_X.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABEAAAAZCAIAAABYXFLAAAAC3ElEQVR4nEWSzW5dRRCEq7p75lxfX2xiSJCRUGDB+z8FK16ANYqIhBLHMc79OTPdxeKYMOvSdNVXxT9+/w0A4QCKKAwApEsSQTpJSdIAIFFipGSAVAAAiAVAQoEwklUAWCYCpqKkqCoAKgEgmUiSKhUIkaRIIatkFoSbWUSzSkAJ2Rijt07aZQ6PRto612iULGxnZuaemSGpSpBUVVXPz880a23JzJzDm/feq+r0fK6qMaekmJe1CAAzsY45n/Pp+XNEF6wvcXt3+3h8enj4eHyco8Z5PS37iKpiuJmNdY4xHj4+/Pnu3Zwl2Os338n06fOH9+//+vJpJHLW+P6HVxHhcAikG2hPj5fHD6fj8XiZ43xc55ofP/399M8D1q4QI6PdBckxhyAJWxUbyWVZ3P14PJ5OJzMrwN3bEr33WMd5Mo0dFlUg+nrRHDws15r88vlI2fXV4frmll2xx/WhxxjDFo+IUgAXklXl7suyVA0z3N/f3//4OmqHVujTd4jLyG/2V7OyEiBPNQlfGPN43n/rb3559fOvP/Wr2F1dr+tqjqqKzJRewkREVVVVKj1sWZabm5v9fs/QVxkAg5FuZgZAyFwTkoEA+m45HG6WZXFvmSIJGUnrvW9LAzDnXNeVZGttm6y7b5c3zfaMjvM4y+TOOcccAwCMmUNGmlWqRhnMGQY3uJmZJHc3s/9Mq6oktdaWZdkObka2QOG9saakQtJkJlJwFOHNvEVRhAEGiARE672TXNe1qlpr7h4REeHuX2fxfxIzkiagxJwyMynhY9QpcUmbx/XEoESzAFBVmQUgLpdLZhK2UXL33W63LEuPtt/vtwxzTrhJJUlibN9IykwZD3c74Sa8+8J+iMs4tzBjS73gyazYuG2+3f3t27fzTULGJvXKzBZmZjJsMhKBemnL3K+u4u5uYTnkcJ7mcR0nh6MUbjBt3GNzvGGJiK2KKhHcxt4YPll4oSfpXy0kEE4lheKLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=17x25 at 0x7FAF3A0E7BE0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data_X, data_y, test_size=0.2, random_state=None, stratify = data_y, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.2, random_state=None, stratify = train_y, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(train_X)\n",
    "val_X = np.array(val_X)\n",
    "test_X = np.array(test_X)\n",
    "train_y = np.squeeze(np.array(train_y))\n",
    "val_y = np.squeeze(np.array(val_y))\n",
    "test_y = np.squeeze(np.array(test_y))\n",
    "y_true = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4020, 28, 28, 3)\n",
      "(4020,)\n",
      "(1006, 28, 28, 3)\n",
      "(1006,)\n",
      "(1257, 28, 28, 3)\n",
      "(1257,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(val_X.shape)\n",
    "print(val_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map_generator(labels):\n",
    "    label2int = {}\n",
    "    int2label = []\n",
    "    set_labels = list(set(labels))\n",
    "    for i in range(len(set_labels)):\n",
    "        label2int[set_labels[i]] = i\n",
    "    for i in label2int.keys():\n",
    "        int2label.append(i)\n",
    "    return label2int, int2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int, int2label = label_map_generator(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [label2int[item] for item in train_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = keras.utils.to_categorical(train_y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1006,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = [label2int[item] for item in val_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1006,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(val_y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = keras.utils.to_categorical(val_y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4020, 28, 28, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "#num_classes = 10\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xinsongdu/.pyenv/versions/miniconda3-latest/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/xinsongdu/.pyenv/versions/miniconda3-latest/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/xinsongdu/.pyenv/versions/miniconda3-latest/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "#model.summary()\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "val_X = val_X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1006, 62)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 62)                7998      \n",
      "=================================================================\n",
      "Total params: 1,207,166\n",
      "Trainable params: 1,207,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 4020 samples, validate on 1006 samples\n",
      "Epoch 1/200\n",
      "4020/4020 [==============================] - 8s - loss: 15.3823 - acc: 0.0383 - val_loss: 15.4561 - val_acc: 0.0408\n",
      "Epoch 2/200\n",
      "4020/4020 [==============================] - 0s - loss: 15.3556 - acc: 0.0400 - val_loss: 15.1814 - val_acc: 0.0467\n",
      "Epoch 3/200\n",
      "4020/4020 [==============================] - 0s - loss: 15.2792 - acc: 0.0425 - val_loss: 15.3752 - val_acc: 0.0447\n",
      "Epoch 4/200\n",
      "4020/4020 [==============================] - 0s - loss: 15.3900 - acc: 0.0423 - val_loss: 15.3971 - val_acc: 0.0447\n",
      "Epoch 5/200\n",
      "4020/4020 [==============================] - 0s - loss: 15.3518 - acc: 0.0445 - val_loss: 15.3971 - val_acc: 0.0447\n",
      "Epoch 6/200\n",
      "4020/4020 [==============================] - 0s - loss: 15.3197 - acc: 0.0453 - val_loss: 15.3971 - val_acc: 0.0447\n",
      "Epoch 7/200\n",
      "4020/4020 [==============================] - 0s - loss: 15.3464 - acc: 0.0410 - val_loss: 15.1957 - val_acc: 0.0398\n",
      "Epoch 8/200\n",
      "4020/4020 [==============================] - 0s - loss: 15.2407 - acc: 0.0470 - val_loss: 15.0544 - val_acc: 0.0537\n",
      "Epoch 9/200\n",
      "4020/4020 [==============================] - 0s - loss: 15.2159 - acc: 0.0498 - val_loss: 15.2385 - val_acc: 0.0467\n",
      "Epoch 10/200\n",
      "4020/4020 [==============================] - 0s - loss: 15.1582 - acc: 0.0485 - val_loss: 15.2879 - val_acc: 0.0457\n",
      "Epoch 11/200\n",
      "4020/4020 [==============================] - 0s - loss: 14.8568 - acc: 0.0502 - val_loss: 14.4634 - val_acc: 0.0596\n",
      "Epoch 12/200\n",
      "4020/4020 [==============================] - 0s - loss: 9.0072 - acc: 0.0425 - val_loss: 4.1355 - val_acc: 0.0527\n",
      "Epoch 13/200\n",
      "4020/4020 [==============================] - 0s - loss: 4.2051 - acc: 0.0520 - val_loss: 4.1152 - val_acc: 0.0736\n",
      "Epoch 14/200\n",
      "4020/4020 [==============================] - 0s - loss: 4.1290 - acc: 0.0587 - val_loss: 4.1007 - val_acc: 0.0765\n",
      "Epoch 15/200\n",
      "4020/4020 [==============================] - 0s - loss: 4.1257 - acc: 0.0642 - val_loss: 4.0982 - val_acc: 0.0736\n",
      "Epoch 16/200\n",
      "4020/4020 [==============================] - 0s - loss: 4.1121 - acc: 0.0679 - val_loss: 4.0825 - val_acc: 0.0736\n",
      "Epoch 17/200\n",
      "4020/4020 [==============================] - 0s - loss: 4.0811 - acc: 0.0711 - val_loss: 4.0519 - val_acc: 0.0915\n",
      "Epoch 18/200\n",
      "4020/4020 [==============================] - 0s - loss: 4.0321 - acc: 0.0711 - val_loss: 4.0350 - val_acc: 0.1004\n",
      "Epoch 19/200\n",
      "4020/4020 [==============================] - 0s - loss: 4.0137 - acc: 0.0823 - val_loss: 3.9788 - val_acc: 0.1083\n",
      "Epoch 20/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.9430 - acc: 0.0935 - val_loss: 3.8854 - val_acc: 0.1243\n",
      "Epoch 21/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.9033 - acc: 0.1037 - val_loss: 3.8344 - val_acc: 0.1501\n",
      "Epoch 22/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.8251 - acc: 0.1219 - val_loss: 3.7925 - val_acc: 0.1501\n",
      "Epoch 23/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.7418 - acc: 0.1301 - val_loss: 3.6909 - val_acc: 0.1759\n",
      "Epoch 24/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.6773 - acc: 0.1473 - val_loss: 3.6268 - val_acc: 0.1988\n",
      "Epoch 25/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.5795 - acc: 0.1612 - val_loss: 3.5820 - val_acc: 0.2107\n",
      "Epoch 26/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.5032 - acc: 0.1789 - val_loss: 3.4686 - val_acc: 0.2276\n",
      "Epoch 27/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.4093 - acc: 0.1933 - val_loss: 3.4319 - val_acc: 0.2455\n",
      "Epoch 28/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.3401 - acc: 0.2107 - val_loss: 3.3858 - val_acc: 0.2575\n",
      "Epoch 29/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.2560 - acc: 0.2219 - val_loss: 3.2804 - val_acc: 0.2644\n",
      "Epoch 30/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.1820 - acc: 0.2408 - val_loss: 3.2119 - val_acc: 0.2763\n",
      "Epoch 31/200\n",
      "4020/4020 [==============================] - 0s - loss: 3.0890 - acc: 0.2639 - val_loss: 3.1870 - val_acc: 0.2793\n",
      "Epoch 32/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.9867 - acc: 0.2714 - val_loss: 3.1186 - val_acc: 0.3002\n",
      "Epoch 33/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.9441 - acc: 0.2878 - val_loss: 3.0601 - val_acc: 0.3072\n",
      "Epoch 34/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.8257 - acc: 0.3085 - val_loss: 3.0167 - val_acc: 0.3280\n",
      "Epoch 35/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.7559 - acc: 0.3234 - val_loss: 2.9700 - val_acc: 0.3400\n",
      "Epoch 36/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.6825 - acc: 0.3316 - val_loss: 2.9127 - val_acc: 0.3549\n",
      "Epoch 37/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.6439 - acc: 0.3408 - val_loss: 2.8843 - val_acc: 0.3489\n",
      "Epoch 38/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.5739 - acc: 0.3570 - val_loss: 2.8262 - val_acc: 0.3618\n",
      "Epoch 39/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.4904 - acc: 0.3662 - val_loss: 2.7889 - val_acc: 0.3698\n",
      "Epoch 40/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.4320 - acc: 0.3900 - val_loss: 2.8252 - val_acc: 0.3757\n",
      "Epoch 41/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.3625 - acc: 0.4097 - val_loss: 2.7502 - val_acc: 0.3887\n",
      "Epoch 42/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.3034 - acc: 0.4072 - val_loss: 2.7336 - val_acc: 0.3857\n",
      "Epoch 43/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.2201 - acc: 0.4241 - val_loss: 2.7224 - val_acc: 0.3986\n",
      "Epoch 44/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.1735 - acc: 0.4373 - val_loss: 2.6970 - val_acc: 0.3946\n",
      "Epoch 45/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.1066 - acc: 0.4530 - val_loss: 2.6454 - val_acc: 0.3996\n",
      "Epoch 46/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.0298 - acc: 0.4664 - val_loss: 2.6309 - val_acc: 0.4135\n",
      "Epoch 47/200\n",
      "4020/4020 [==============================] - 0s - loss: 2.0025 - acc: 0.4761 - val_loss: 2.6190 - val_acc: 0.4115\n",
      "Epoch 48/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.9315 - acc: 0.4975 - val_loss: 2.6083 - val_acc: 0.4264\n",
      "Epoch 49/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.8945 - acc: 0.5020 - val_loss: 2.6195 - val_acc: 0.4195\n",
      "Epoch 50/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.7934 - acc: 0.5221 - val_loss: 2.5927 - val_acc: 0.4294\n",
      "Epoch 51/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.7889 - acc: 0.5306 - val_loss: 2.5342 - val_acc: 0.4404\n",
      "Epoch 52/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.7323 - acc: 0.5313 - val_loss: 2.5537 - val_acc: 0.4374\n",
      "Epoch 53/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.7209 - acc: 0.5274 - val_loss: 2.4976 - val_acc: 0.4463\n",
      "Epoch 54/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.6398 - acc: 0.5552 - val_loss: 2.4926 - val_acc: 0.4503\n",
      "Epoch 55/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.5788 - acc: 0.5709 - val_loss: 2.5015 - val_acc: 0.4592\n",
      "Epoch 56/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.5746 - acc: 0.5734 - val_loss: 2.4606 - val_acc: 0.4602\n",
      "Epoch 57/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.4995 - acc: 0.5913 - val_loss: 2.5134 - val_acc: 0.4553\n",
      "Epoch 58/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.4238 - acc: 0.6085 - val_loss: 2.4976 - val_acc: 0.4682\n",
      "Epoch 59/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.4684 - acc: 0.5968 - val_loss: 2.4271 - val_acc: 0.4622\n",
      "Epoch 60/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.4056 - acc: 0.6117 - val_loss: 2.4242 - val_acc: 0.4692\n",
      "Epoch 61/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.3602 - acc: 0.6254 - val_loss: 2.4862 - val_acc: 0.4732\n",
      "Epoch 62/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.3223 - acc: 0.6378 - val_loss: 2.4211 - val_acc: 0.4821\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4020/4020 [==============================] - 0s - loss: 1.2921 - acc: 0.6388 - val_loss: 2.4164 - val_acc: 0.4911\n",
      "Epoch 64/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.2681 - acc: 0.6480 - val_loss: 2.4140 - val_acc: 0.4861\n",
      "Epoch 65/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.1948 - acc: 0.6689 - val_loss: 2.4060 - val_acc: 0.4950\n",
      "Epoch 66/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.1948 - acc: 0.6637 - val_loss: 2.3948 - val_acc: 0.4920\n",
      "Epoch 67/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.1355 - acc: 0.6836 - val_loss: 2.3982 - val_acc: 0.4940\n",
      "Epoch 68/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.1374 - acc: 0.6821 - val_loss: 2.4175 - val_acc: 0.4920\n",
      "Epoch 69/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.0585 - acc: 0.6988 - val_loss: 2.4209 - val_acc: 0.4940\n",
      "Epoch 70/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.0827 - acc: 0.6928 - val_loss: 2.3765 - val_acc: 0.4940\n",
      "Epoch 71/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.0288 - acc: 0.7057 - val_loss: 2.3841 - val_acc: 0.4960\n",
      "Epoch 72/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.9972 - acc: 0.7184 - val_loss: 2.3249 - val_acc: 0.5080\n",
      "Epoch 73/200\n",
      "4020/4020 [==============================] - 0s - loss: 1.0020 - acc: 0.7216 - val_loss: 2.4690 - val_acc: 0.5050\n",
      "Epoch 74/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.9443 - acc: 0.7361 - val_loss: 2.5233 - val_acc: 0.5070\n",
      "Epoch 75/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.9158 - acc: 0.7346 - val_loss: 2.4463 - val_acc: 0.5089\n",
      "Epoch 76/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.9099 - acc: 0.7485 - val_loss: 2.4932 - val_acc: 0.5129\n",
      "Epoch 77/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.8906 - acc: 0.7463 - val_loss: 2.5346 - val_acc: 0.5020\n",
      "Epoch 78/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.8558 - acc: 0.7547 - val_loss: 2.3193 - val_acc: 0.5070\n",
      "Epoch 79/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.8700 - acc: 0.7483 - val_loss: 2.3683 - val_acc: 0.5278\n",
      "Epoch 80/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.8294 - acc: 0.7627 - val_loss: 2.4681 - val_acc: 0.5209\n",
      "Epoch 81/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.7886 - acc: 0.7751 - val_loss: 2.5543 - val_acc: 0.5169\n",
      "Epoch 82/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.7888 - acc: 0.7736 - val_loss: 2.4755 - val_acc: 0.5169\n",
      "Epoch 83/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.7679 - acc: 0.7803 - val_loss: 2.3155 - val_acc: 0.5209\n",
      "Epoch 84/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.7362 - acc: 0.7841 - val_loss: 2.3394 - val_acc: 0.5179\n",
      "Epoch 85/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.7421 - acc: 0.7900 - val_loss: 2.4117 - val_acc: 0.5159\n",
      "Epoch 86/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.7221 - acc: 0.7928 - val_loss: 2.4255 - val_acc: 0.5298\n",
      "Epoch 87/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.6971 - acc: 0.7920 - val_loss: 2.4532 - val_acc: 0.5288\n",
      "Epoch 88/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.7019 - acc: 0.7925 - val_loss: 2.3467 - val_acc: 0.5288\n",
      "Epoch 89/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.6608 - acc: 0.8050 - val_loss: 2.2628 - val_acc: 0.5219\n",
      "Epoch 90/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.6730 - acc: 0.8060 - val_loss: 2.4164 - val_acc: 0.5179\n",
      "Epoch 91/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.6381 - acc: 0.8114 - val_loss: 2.3466 - val_acc: 0.5398\n",
      "Epoch 92/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.6317 - acc: 0.8197 - val_loss: 2.4865 - val_acc: 0.5308\n",
      "Epoch 93/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.6331 - acc: 0.8174 - val_loss: 2.5049 - val_acc: 0.5348\n",
      "Epoch 94/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.6137 - acc: 0.8194 - val_loss: 2.4385 - val_acc: 0.5239\n",
      "Epoch 95/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.5935 - acc: 0.8211 - val_loss: 2.4607 - val_acc: 0.5268\n",
      "Epoch 96/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.6012 - acc: 0.8236 - val_loss: 2.4458 - val_acc: 0.5258\n",
      "Epoch 97/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.5593 - acc: 0.8371 - val_loss: 2.4580 - val_acc: 0.5388\n",
      "Epoch 98/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.5414 - acc: 0.8398 - val_loss: 2.5498 - val_acc: 0.5358\n",
      "Epoch 99/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.5847 - acc: 0.8276 - val_loss: 2.4989 - val_acc: 0.5427\n",
      "Epoch 100/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.5197 - acc: 0.8448 - val_loss: 2.5489 - val_acc: 0.5398\n",
      "Epoch 101/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.5131 - acc: 0.8478 - val_loss: 2.6362 - val_acc: 0.5437\n",
      "Epoch 102/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.5219 - acc: 0.8480 - val_loss: 2.5506 - val_acc: 0.5328\n",
      "Epoch 103/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.5073 - acc: 0.8550 - val_loss: 2.5095 - val_acc: 0.5408\n",
      "Epoch 104/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4859 - acc: 0.8592 - val_loss: 2.5305 - val_acc: 0.5338\n",
      "Epoch 105/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4986 - acc: 0.8478 - val_loss: 2.6067 - val_acc: 0.5378\n",
      "Epoch 106/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4641 - acc: 0.8652 - val_loss: 2.5437 - val_acc: 0.5318\n",
      "Epoch 107/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4703 - acc: 0.8632 - val_loss: 2.6187 - val_acc: 0.5378\n",
      "Epoch 108/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4376 - acc: 0.8711 - val_loss: 2.6940 - val_acc: 0.5527\n",
      "Epoch 109/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4589 - acc: 0.8679 - val_loss: 2.6430 - val_acc: 0.5437\n",
      "Epoch 110/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4280 - acc: 0.8711 - val_loss: 2.5558 - val_acc: 0.5467\n",
      "Epoch 111/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4382 - acc: 0.8699 - val_loss: 2.7201 - val_acc: 0.5427\n",
      "Epoch 112/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4394 - acc: 0.8684 - val_loss: 2.2812 - val_acc: 0.5417\n",
      "Epoch 113/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4151 - acc: 0.8813 - val_loss: 2.6778 - val_acc: 0.5417\n",
      "Epoch 114/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4122 - acc: 0.8806 - val_loss: 2.5879 - val_acc: 0.5417\n",
      "Epoch 115/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3970 - acc: 0.8853 - val_loss: 2.5167 - val_acc: 0.5437\n",
      "Epoch 116/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.4213 - acc: 0.8784 - val_loss: 2.6354 - val_acc: 0.5487\n",
      "Epoch 117/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3901 - acc: 0.8848 - val_loss: 2.5369 - val_acc: 0.5497\n",
      "Epoch 118/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3891 - acc: 0.8818 - val_loss: 2.4377 - val_acc: 0.5417\n",
      "Epoch 119/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3801 - acc: 0.8896 - val_loss: 2.4770 - val_acc: 0.5517\n",
      "Epoch 120/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3671 - acc: 0.8925 - val_loss: 2.4500 - val_acc: 0.5487\n",
      "Epoch 121/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3450 - acc: 0.8985 - val_loss: 2.5307 - val_acc: 0.5378\n",
      "Epoch 122/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3605 - acc: 0.8923 - val_loss: 2.6625 - val_acc: 0.5408\n",
      "Epoch 123/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3382 - acc: 0.9002 - val_loss: 2.7584 - val_acc: 0.5457\n",
      "Epoch 124/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3615 - acc: 0.8953 - val_loss: 2.8561 - val_acc: 0.5408\n",
      "Epoch 125/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3434 - acc: 0.8980 - val_loss: 2.6447 - val_acc: 0.5487\n",
      "Epoch 126/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3349 - acc: 0.8988 - val_loss: 2.6812 - val_acc: 0.5427\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4020/4020 [==============================] - 0s - loss: 0.3417 - acc: 0.9007 - val_loss: 2.8690 - val_acc: 0.5457\n",
      "Epoch 128/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3393 - acc: 0.9005 - val_loss: 2.7490 - val_acc: 0.5487\n",
      "Epoch 129/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3236 - acc: 0.9045 - val_loss: 2.6153 - val_acc: 0.5507\n",
      "Epoch 130/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3124 - acc: 0.9100 - val_loss: 2.5259 - val_acc: 0.5487\n",
      "Epoch 131/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3265 - acc: 0.9057 - val_loss: 2.6882 - val_acc: 0.5437\n",
      "Epoch 132/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3334 - acc: 0.9032 - val_loss: 2.5995 - val_acc: 0.5517\n",
      "Epoch 133/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2934 - acc: 0.9144 - val_loss: 2.6290 - val_acc: 0.5557\n",
      "Epoch 134/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3320 - acc: 0.9035 - val_loss: 2.7143 - val_acc: 0.5557\n",
      "Epoch 135/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2787 - acc: 0.9142 - val_loss: 2.9538 - val_acc: 0.5417\n",
      "Epoch 136/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2912 - acc: 0.9139 - val_loss: 2.7485 - val_acc: 0.5626\n",
      "Epoch 137/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.3044 - acc: 0.9132 - val_loss: 2.4772 - val_acc: 0.5577\n",
      "Epoch 138/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2775 - acc: 0.9211 - val_loss: 2.7494 - val_acc: 0.5567\n",
      "Epoch 139/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2934 - acc: 0.9167 - val_loss: 2.5253 - val_acc: 0.5616\n",
      "Epoch 140/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2815 - acc: 0.9179 - val_loss: 2.4184 - val_acc: 0.5467\n",
      "Epoch 141/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2731 - acc: 0.9194 - val_loss: 2.5138 - val_acc: 0.5567\n",
      "Epoch 142/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2586 - acc: 0.9294 - val_loss: 2.5310 - val_acc: 0.5596\n",
      "Epoch 143/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2714 - acc: 0.9177 - val_loss: 2.5811 - val_acc: 0.5626\n",
      "Epoch 144/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2746 - acc: 0.9214 - val_loss: 2.7482 - val_acc: 0.5716\n",
      "Epoch 145/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2700 - acc: 0.9231 - val_loss: 2.4024 - val_acc: 0.5616\n",
      "Epoch 146/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2742 - acc: 0.9147 - val_loss: 2.6823 - val_acc: 0.5626\n",
      "Epoch 147/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2531 - acc: 0.9259 - val_loss: 2.6559 - val_acc: 0.5606\n",
      "Epoch 148/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2589 - acc: 0.9256 - val_loss: 2.6337 - val_acc: 0.5596\n",
      "Epoch 149/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2510 - acc: 0.9256 - val_loss: 2.7847 - val_acc: 0.5586\n",
      "Epoch 150/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2562 - acc: 0.9231 - val_loss: 2.7377 - val_acc: 0.5686\n",
      "Epoch 151/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2697 - acc: 0.9234 - val_loss: 2.8029 - val_acc: 0.5636\n",
      "Epoch 152/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2693 - acc: 0.9224 - val_loss: 2.8496 - val_acc: 0.5636\n",
      "Epoch 153/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2479 - acc: 0.9299 - val_loss: 2.8512 - val_acc: 0.5646\n",
      "Epoch 154/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2271 - acc: 0.9328 - val_loss: 2.8527 - val_acc: 0.5557\n",
      "Epoch 155/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2212 - acc: 0.9353 - val_loss: 2.7146 - val_acc: 0.5676\n",
      "Epoch 156/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2431 - acc: 0.9254 - val_loss: 2.4137 - val_acc: 0.5646\n",
      "Epoch 157/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2238 - acc: 0.9356 - val_loss: 2.7937 - val_acc: 0.5706\n",
      "Epoch 158/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2171 - acc: 0.9363 - val_loss: 2.9182 - val_acc: 0.5577\n",
      "Epoch 159/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2253 - acc: 0.9323 - val_loss: 2.9117 - val_acc: 0.5656\n",
      "Epoch 160/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2307 - acc: 0.9291 - val_loss: 2.6275 - val_acc: 0.5557\n",
      "Epoch 161/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2375 - acc: 0.9303 - val_loss: 3.1813 - val_acc: 0.5517\n",
      "Epoch 162/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2265 - acc: 0.9376 - val_loss: 2.5933 - val_acc: 0.5606\n",
      "Epoch 163/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2108 - acc: 0.9358 - val_loss: 2.8558 - val_acc: 0.5517\n",
      "Epoch 164/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2078 - acc: 0.9391 - val_loss: 2.7055 - val_acc: 0.5547\n",
      "Epoch 165/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2249 - acc: 0.9331 - val_loss: 2.5825 - val_acc: 0.5716\n",
      "Epoch 166/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2116 - acc: 0.9363 - val_loss: 2.4634 - val_acc: 0.5547\n",
      "Epoch 167/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2339 - acc: 0.9301 - val_loss: 2.6961 - val_acc: 0.5616\n",
      "Epoch 168/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2044 - acc: 0.9353 - val_loss: 2.8858 - val_acc: 0.5736\n",
      "Epoch 169/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2123 - acc: 0.9420 - val_loss: 2.7215 - val_acc: 0.5626\n",
      "Epoch 170/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2035 - acc: 0.9388 - val_loss: 2.6249 - val_acc: 0.5736\n",
      "Epoch 171/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2163 - acc: 0.9388 - val_loss: 2.9737 - val_acc: 0.5666\n",
      "Epoch 172/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2037 - acc: 0.9408 - val_loss: 2.8102 - val_acc: 0.5755\n",
      "Epoch 173/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1976 - acc: 0.9418 - val_loss: 2.9605 - val_acc: 0.5577\n",
      "Epoch 174/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2026 - acc: 0.9383 - val_loss: 2.5676 - val_acc: 0.5696\n",
      "Epoch 175/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1929 - acc: 0.9460 - val_loss: 2.9603 - val_acc: 0.5706\n",
      "Epoch 176/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1897 - acc: 0.9445 - val_loss: 3.0318 - val_acc: 0.5666\n",
      "Epoch 177/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2015 - acc: 0.9386 - val_loss: 2.7973 - val_acc: 0.5785\n",
      "Epoch 178/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2035 - acc: 0.9420 - val_loss: 2.5382 - val_acc: 0.5706\n",
      "Epoch 179/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2062 - acc: 0.9415 - val_loss: 3.0193 - val_acc: 0.5567\n",
      "Epoch 180/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2082 - acc: 0.9396 - val_loss: 2.8578 - val_acc: 0.5706\n",
      "Epoch 181/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2046 - acc: 0.9386 - val_loss: 3.3357 - val_acc: 0.5656\n",
      "Epoch 182/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2160 - acc: 0.9450 - val_loss: 2.8080 - val_acc: 0.5676\n",
      "Epoch 183/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2029 - acc: 0.9420 - val_loss: 2.7334 - val_acc: 0.5696\n",
      "Epoch 184/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1953 - acc: 0.9458 - val_loss: 2.9683 - val_acc: 0.5676\n",
      "Epoch 185/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1913 - acc: 0.9465 - val_loss: 2.5191 - val_acc: 0.5616\n",
      "Epoch 186/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.2125 - acc: 0.9430 - val_loss: 2.7000 - val_acc: 0.5636\n",
      "Epoch 187/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1904 - acc: 0.9433 - val_loss: 3.1872 - val_acc: 0.5706\n",
      "Epoch 188/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1719 - acc: 0.9495 - val_loss: 2.8405 - val_acc: 0.5666\n",
      "Epoch 189/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1641 - acc: 0.9520 - val_loss: 2.8299 - val_acc: 0.5666\n",
      "Epoch 190/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1865 - acc: 0.9478 - val_loss: 3.2907 - val_acc: 0.5596\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4020/4020 [==============================] - 0s - loss: 0.1782 - acc: 0.9515 - val_loss: 2.7010 - val_acc: 0.5696\n",
      "Epoch 192/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1892 - acc: 0.9498 - val_loss: 2.8330 - val_acc: 0.5706\n",
      "Epoch 193/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1626 - acc: 0.9522 - val_loss: 2.8516 - val_acc: 0.5755\n",
      "Epoch 194/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1814 - acc: 0.9483 - val_loss: 3.1720 - val_acc: 0.5636\n",
      "Epoch 195/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1865 - acc: 0.9485 - val_loss: 2.8574 - val_acc: 0.5557\n",
      "Epoch 196/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1943 - acc: 0.9460 - val_loss: 2.5967 - val_acc: 0.5616\n",
      "Epoch 197/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1640 - acc: 0.9535 - val_loss: 3.2930 - val_acc: 0.5706\n",
      "Epoch 198/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1706 - acc: 0.9490 - val_loss: 2.8866 - val_acc: 0.5666\n",
      "Epoch 199/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1691 - acc: 0.9490 - val_loss: 3.2057 - val_acc: 0.5726\n",
      "Epoch 200/200\n",
      "4020/4020 [==============================] - 0s - loss: 0.1655 - acc: 0.9500 - val_loss: 3.2088 - val_acc: 0.5676\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(plt.plot(history.history['loss']), plt.plot(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Neural Network with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['n', 'U', '5', ..., 'Q', 'H', 'A'], dtype='<U1')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216/1257 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [int2label[item] for item in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "733"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_pred == y_true).count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1257"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9697619047619047"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
